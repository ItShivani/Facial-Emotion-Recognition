{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xqT6lrmaAS8Y",
        "outputId": "9f3fa01e-5564-428c-b0ea-27fcbb3fc013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks')\n",
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip /content/drive/MyDrive/dlp.zip"
      ],
      "metadata": {
        "id": "qigwWudbZYoO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y6nXa1g2BBNM"
      },
      "outputs": [],
      "source": [
        "# TRAIN_DIR = '/content/drive/MyDrive/Colab Notebooks/train'\n",
        "# TEST_DIR = '/content/drive/MyDrive/Colab Notebooks/test'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization, Activation, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Define the paths to the train and test data directories\n",
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/train/'\n",
        "test_dir = '/content/drive/MyDrive/Colab Notebooks/test/'\n",
        "\n",
        "# Define a mapping between emotion labels and numeric labels\n",
        "emotion_mapping = {\n",
        "    'angry': 0,\n",
        "    'disgust': 1,\n",
        "    'fear': 2,\n",
        "    'happy': 3,\n",
        "    'sad': 4,\n",
        "    'surprise': 5,\n",
        "    'neutral': 6\n",
        "}\n",
        "\n",
        "# Initialize lists to store image data and labels\n",
        "image_data = []\n",
        "labels = []"
      ],
      "metadata": {
        "id": "042DeUDFCWUP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess images from a directory\n",
        "def load_and_preprocess_images(directory, emotion_label_numeric):\n",
        "    for image_file in os.listdir(directory):\n",
        "        image_path = os.path.join(directory, image_file)\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "        image = cv2.resize(image, (48, 48))  # Resize to 48x48 pixels\n",
        "\n",
        "        # Append the image data and label to the lists\n",
        "        image_data.append(image)\n",
        "        labels.append(emotion_label_numeric)\n",
        "\n",
        "# Iterate through each folder (emotion label) in the train directory\n",
        "for emotion_label in os.listdir(train_dir):\n",
        "    emotion_dir = os.path.join(train_dir, emotion_label)\n",
        "\n",
        "    # Check if it's a directory and if it exists in the emotion mapping\n",
        "    if os.path.isdir(emotion_dir) and emotion_label in emotion_mapping:\n",
        "        emotion_label_numeric = emotion_mapping[emotion_label]\n",
        "\n",
        "        # Load and preprocess images from the current emotion folder\n",
        "        load_and_preprocess_images(emotion_dir, emotion_label_numeric)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "x_data = np.array(image_data)\n",
        "y_data = np.array(labels)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_data = to_categorical(y_data, num_classes=7)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the images to have 3 channels (grayscale to RGB)\n",
        "x_train = np.stack((x_train,) * 3, axis=-1)\n",
        "x_test = np.stack((x_test,) * 3, axis=-1)"
      ],
      "metadata": {
        "id": "M8HATWP2n8rm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        ")\n",
        "\n",
        "# Define the ResNet50 model from scratch\n",
        "def resnet_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True):\n",
        "    shortcut = x\n",
        "    if conv_shortcut:\n",
        "        shortcut = Conv2D(filters, (1, 1), strides=stride)(shortcut)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = tf.keras.layers.add([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "input_shape = (48, 48, 3)\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "x = Conv2D(64, (7, 7), strides=2, padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n",
        "\n",
        "x = resnet_block(x, 64, conv_shortcut=False)\n",
        "x = resnet_block(x, 64)\n",
        "x = resnet_block(x, 64)\n",
        "\n",
        "x = resnet_block(x, 128, stride=2)\n",
        "x = resnet_block(x, 128)\n",
        "x = resnet_block(x, 128)\n",
        "x = resnet_block(x, 128)\n",
        "\n",
        "x = resnet_block(x, 256, stride=2)\n",
        "x = resnet_block(x, 256)\n",
        "x = resnet_block(x, 256)\n",
        "x = resnet_block(x, 256)\n",
        "x = resnet_block(x, 256)\n",
        "\n",
        "x = resnet_block(x, 512, stride=2)\n",
        "x = resnet_block(x, 512)\n",
        "x = resnet_block(x, 512)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(7, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Learning Rate Schedule\n",
        "def learning_rate_schedule(epoch):\n",
        "    if epoch < 10:\n",
        "        return 0.001\n",
        "    elif epoch < 20:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(learning_rate_schedule)\n",
        "\n",
        "# Train the model with early stopping and learning rate schedule\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "   datagen.flow(x_train, y_train, batch_size=128),\n",
        "   epochs=50,\n",
        "   validation_data=(x_test, y_test),\n",
        "   callbacks=[early_stopping, lr_scheduler],\n",
        "   verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lWeIMCldyeg",
        "outputId": "df048229-98e1-4dbb-dd03-638f72a87993"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "180/180 [==============================] - 70s 180ms/step - loss: 1.7880 - accuracy: 0.2729 - val_loss: 1.7646 - val_accuracy: 0.3194 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "180/180 [==============================] - 30s 166ms/step - loss: 1.6551 - accuracy: 0.3428 - val_loss: 1.7900 - val_accuracy: 0.3553 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "180/180 [==============================] - 30s 165ms/step - loss: 1.5650 - accuracy: 0.3848 - val_loss: 2.0703 - val_accuracy: 0.3474 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "180/180 [==============================] - 31s 169ms/step - loss: 1.5002 - accuracy: 0.4131 - val_loss: 2.3232 - val_accuracy: 0.3581 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "180/180 [==============================] - 30s 169ms/step - loss: 1.4292 - accuracy: 0.4499 - val_loss: 1.8931 - val_accuracy: 0.3993 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "180/180 [==============================] - 29s 160ms/step - loss: 1.3758 - accuracy: 0.4723 - val_loss: 1.8131 - val_accuracy: 0.4582 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "180/180 [==============================] - 30s 165ms/step - loss: 1.3399 - accuracy: 0.4868 - val_loss: 1.4464 - val_accuracy: 0.4824 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "180/180 [==============================] - 31s 171ms/step - loss: 1.3023 - accuracy: 0.5040 - val_loss: 1.3641 - val_accuracy: 0.4932 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "180/180 [==============================] - 29s 161ms/step - loss: 1.2703 - accuracy: 0.5163 - val_loss: 1.7293 - val_accuracy: 0.4343 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "180/180 [==============================] - 30s 165ms/step - loss: 1.2540 - accuracy: 0.5236 - val_loss: 1.7672 - val_accuracy: 0.4063 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "180/180 [==============================] - 31s 170ms/step - loss: 1.1574 - accuracy: 0.5627 - val_loss: 1.1126 - val_accuracy: 0.5848 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "180/180 [==============================] - 29s 163ms/step - loss: 1.1312 - accuracy: 0.5750 - val_loss: 1.1487 - val_accuracy: 0.5670 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "180/180 [==============================] - 31s 169ms/step - loss: 1.1093 - accuracy: 0.5798 - val_loss: 1.1028 - val_accuracy: 0.5883 - lr: 1.0000e-04\n",
            "Epoch 14/50\n",
            "180/180 [==============================] - 31s 171ms/step - loss: 1.0999 - accuracy: 0.5824 - val_loss: 1.0963 - val_accuracy: 0.5902 - lr: 1.0000e-04\n",
            "Epoch 15/50\n",
            "180/180 [==============================] - 29s 162ms/step - loss: 1.0953 - accuracy: 0.5894 - val_loss: 1.0941 - val_accuracy: 0.5927 - lr: 1.0000e-04\n",
            "Epoch 16/50\n",
            "180/180 [==============================] - 29s 158ms/step - loss: 1.0870 - accuracy: 0.5873 - val_loss: 1.0985 - val_accuracy: 0.5888 - lr: 1.0000e-04\n",
            "Epoch 17/50\n",
            "180/180 [==============================] - 31s 171ms/step - loss: 1.0788 - accuracy: 0.5925 - val_loss: 1.0925 - val_accuracy: 0.5946 - lr: 1.0000e-04\n",
            "Epoch 18/50\n",
            "180/180 [==============================] - 31s 170ms/step - loss: 1.0696 - accuracy: 0.5957 - val_loss: 1.0640 - val_accuracy: 0.6038 - lr: 1.0000e-04\n",
            "Epoch 19/50\n",
            "180/180 [==============================] - 30s 166ms/step - loss: 1.0667 - accuracy: 0.5958 - val_loss: 1.0645 - val_accuracy: 0.6059 - lr: 1.0000e-04\n",
            "Epoch 20/50\n",
            "180/180 [==============================] - 29s 158ms/step - loss: 1.0545 - accuracy: 0.6001 - val_loss: 1.1791 - val_accuracy: 0.5521 - lr: 1.0000e-04\n",
            "Epoch 21/50\n",
            "180/180 [==============================] - 29s 162ms/step - loss: 1.0339 - accuracy: 0.6101 - val_loss: 1.0496 - val_accuracy: 0.6106 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "180/180 [==============================] - 31s 173ms/step - loss: 1.0268 - accuracy: 0.6105 - val_loss: 1.0542 - val_accuracy: 0.6097 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "180/180 [==============================] - 31s 172ms/step - loss: 1.0204 - accuracy: 0.6153 - val_loss: 1.0501 - val_accuracy: 0.6139 - lr: 1.0000e-05\n",
            "Epoch 24/50\n",
            "180/180 [==============================] - 30s 166ms/step - loss: 1.0228 - accuracy: 0.6136 - val_loss: 1.0490 - val_accuracy: 0.6141 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "180/180 [==============================] - 28s 156ms/step - loss: 1.0140 - accuracy: 0.6174 - val_loss: 1.0519 - val_accuracy: 0.6116 - lr: 1.0000e-05\n",
            "Epoch 26/50\n",
            "180/180 [==============================] - 30s 163ms/step - loss: 1.0197 - accuracy: 0.6134 - val_loss: 1.0496 - val_accuracy: 0.6123 - lr: 1.0000e-05\n",
            "Epoch 27/50\n",
            "180/180 [==============================] - 30s 169ms/step - loss: 1.0145 - accuracy: 0.6140 - val_loss: 1.0472 - val_accuracy: 0.6163 - lr: 1.0000e-05\n",
            "Epoch 28/50\n",
            "180/180 [==============================] - 31s 170ms/step - loss: 1.0185 - accuracy: 0.6143 - val_loss: 1.0466 - val_accuracy: 0.6174 - lr: 1.0000e-05\n",
            "Epoch 29/50\n",
            "180/180 [==============================] - 29s 162ms/step - loss: 1.0159 - accuracy: 0.6145 - val_loss: 1.0472 - val_accuracy: 0.6156 - lr: 1.0000e-05\n",
            "Epoch 30/50\n",
            "180/180 [==============================] - 30s 164ms/step - loss: 1.0147 - accuracy: 0.6164 - val_loss: 1.0426 - val_accuracy: 0.6156 - lr: 1.0000e-05\n",
            "Epoch 31/50\n",
            "180/180 [==============================] - 31s 173ms/step - loss: 1.0097 - accuracy: 0.6191 - val_loss: 1.0432 - val_accuracy: 0.6141 - lr: 1.0000e-05\n",
            "Epoch 32/50\n",
            "180/180 [==============================] - 31s 170ms/step - loss: 1.0129 - accuracy: 0.6144 - val_loss: 1.0412 - val_accuracy: 0.6186 - lr: 1.0000e-05\n",
            "Epoch 33/50\n",
            "180/180 [==============================] - 30s 166ms/step - loss: 1.0060 - accuracy: 0.6189 - val_loss: 1.0420 - val_accuracy: 0.6158 - lr: 1.0000e-05\n",
            "Epoch 34/50\n",
            "180/180 [==============================] - 30s 164ms/step - loss: 1.0100 - accuracy: 0.6178 - val_loss: 1.0428 - val_accuracy: 0.6181 - lr: 1.0000e-05\n",
            "Epoch 35/50\n",
            "180/180 [==============================] - 31s 174ms/step - loss: 1.0103 - accuracy: 0.6185 - val_loss: 1.0508 - val_accuracy: 0.6165 - lr: 1.0000e-05\n",
            "Epoch 36/50\n",
            "180/180 [==============================] - 30s 167ms/step - loss: 1.0112 - accuracy: 0.6161 - val_loss: 1.0507 - val_accuracy: 0.6148 - lr: 1.0000e-05\n",
            "Epoch 37/50\n",
            "180/180 [==============================] - 29s 164ms/step - loss: 1.0032 - accuracy: 0.6221 - val_loss: 1.0446 - val_accuracy: 0.6160 - lr: 1.0000e-05\n",
            "Epoch 38/50\n",
            "180/180 [==============================] - 30s 167ms/step - loss: 1.0060 - accuracy: 0.6197 - val_loss: 1.0412 - val_accuracy: 0.6186 - lr: 1.0000e-05\n",
            "Epoch 39/50\n",
            "180/180 [==============================] - 30s 168ms/step - loss: 1.0008 - accuracy: 0.6208 - val_loss: 1.0377 - val_accuracy: 0.6174 - lr: 1.0000e-05\n",
            "Epoch 40/50\n",
            "180/180 [==============================] - 31s 170ms/step - loss: 1.0037 - accuracy: 0.6206 - val_loss: 1.0364 - val_accuracy: 0.6188 - lr: 1.0000e-05\n",
            "Epoch 41/50\n",
            "180/180 [==============================] - 30s 165ms/step - loss: 1.0015 - accuracy: 0.6212 - val_loss: 1.0366 - val_accuracy: 0.6188 - lr: 1.0000e-05\n",
            "Epoch 42/50\n",
            "180/180 [==============================] - 28s 157ms/step - loss: 1.0002 - accuracy: 0.6234 - val_loss: 1.0359 - val_accuracy: 0.6198 - lr: 1.0000e-05\n",
            "Epoch 43/50\n",
            "180/180 [==============================] - 29s 163ms/step - loss: 0.9966 - accuracy: 0.6218 - val_loss: 1.0385 - val_accuracy: 0.6181 - lr: 1.0000e-05\n",
            "Epoch 44/50\n",
            "180/180 [==============================] - 30s 169ms/step - loss: 0.9986 - accuracy: 0.6235 - val_loss: 1.0363 - val_accuracy: 0.6196 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "180/180 [==============================] - 29s 159ms/step - loss: 0.9989 - accuracy: 0.6253 - val_loss: 1.0507 - val_accuracy: 0.6151 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "180/180 [==============================] - 29s 159ms/step - loss: 0.9959 - accuracy: 0.6230 - val_loss: 1.0394 - val_accuracy: 0.6212 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "180/180 [==============================] - 30s 168ms/step - loss: 1.0026 - accuracy: 0.6212 - val_loss: 1.0423 - val_accuracy: 0.6176 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "180/180 [==============================] - 30s 168ms/step - loss: 0.9915 - accuracy: 0.6272 - val_loss: 1.0371 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "180/180 [==============================] - 28s 155ms/step - loss: 0.9987 - accuracy: 0.6205 - val_loss: 1.0360 - val_accuracy: 0.6184 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "180/180 [==============================] - 30s 165ms/step - loss: 0.9949 - accuracy: 0.6251 - val_loss: 1.0368 - val_accuracy: 0.6230 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model and print test accuracy\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {(test_accuracy) * 100:.2f}%\")\n",
        "\n",
        "# Calculate the training accuracy\n",
        "train_loss, train_accuracy = model.evaluate(x_train, y_train)\n",
        "print(f\"Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Training Accuracy: {(train_accuracy) * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcD_yoRuYnMn",
        "outputId": "7cbe90f2-7f5c-4a9e-ec25-2430e5161258"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180/180 [==============================] - 3s 14ms/step - loss: 1.0368 - accuracy: 0.6230\n",
            "Test Loss: 1.0368\n",
            "Test Accuracy: 62.30%\n",
            "718/718 [==============================] - 10s 14ms/step - loss: 0.9132 - accuracy: 0.6573\n",
            "Training Loss: 0.9132\n",
            "Training Accuracy: 65.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(test_loss, label='Validation Loss')\n",
        "plt.title('Loss Curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy, label='Training Accuracy')\n",
        "plt.plot(test_accuracy, label='Validation Accuracy')\n",
        "plt.title('Accuracy Curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BR700PY2sdgN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}